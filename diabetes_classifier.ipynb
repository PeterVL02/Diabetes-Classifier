{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import os\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch.cuda\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_QNet(nn.Module):\n",
    "    def __init__(self, inputs):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        self.linear1 = nn.Linear(inputs, 256)\n",
    "        self.linear2 = nn.Linear(256,512)\n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.linear4 = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.linear1(x))\n",
    "        x = F.tanh(self.linear2(x))\n",
    "        x = F.tanh(self.linear3(x))\n",
    "        x = F.tanh(self.linear4(x))\n",
    "        return x\n",
    "    \n",
    "    def save(self, file_name='model.pth', index=0):\n",
    "        model_folder_path = './Classifier_models/model' \n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        complete_file_name = f\"{index}_{file_name}\"\n",
    "        file_path = os.path.join(model_folder_path, complete_file_name)\n",
    "        \n",
    "        torch.save(self.state_dict(), file_path)\n",
    "    \n",
    "class QTrainer:\n",
    "    def __init__(self, model, lr):\n",
    "        self.lr = lr\n",
    "        self.model = model\n",
    "        self.device = model.device\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def train_step(self, state, action, reward, done, outcome):\n",
    "        state = torch.tensor(np.array(state), dtype=torch.float).to(self.device)\n",
    "        action = torch.tensor(np.array(action), dtype=torch.long).to(self.device)\n",
    "        reward = torch.tensor(np.array(reward), dtype=torch.float).to(self.device)\n",
    "        # (n, x)\n",
    "\n",
    "        if len(state.shape) == 1:\n",
    "            # (1, x)\n",
    "            state = torch.unsqueeze(state, 0)\n",
    "            action = torch.unsqueeze(action, 0)\n",
    "            reward = torch.unsqueeze(reward, 0)\n",
    "            done = (done, )\n",
    "\n",
    "        # 1: predicted Q values with current state\n",
    "        pred = self.model(state)\n",
    "        target = pred.clone()\n",
    "        \n",
    "        if outcome[0].item() == 1:\n",
    "            target[0,0] = 1\n",
    "            target[0,1] = 0\n",
    "        else:\n",
    "            target[0,0] = 0\n",
    "            target[0,1] = 1\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        ## Calculate MSE loss on target and prediction\n",
    "        loss = self.criterion(target, pred)\n",
    "        loss.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "\n",
    "## Agent tager filepath som input hvis man vil køre en model, der allerede er trænet.\n",
    "class Agent:\n",
    "    def __init__(self, inputs, file_path=None, training=True, device=None, \n",
    "                 learning_rate=0.01, model_name='testing', data=None):\n",
    "        self.data = data\n",
    "        self.MAX_MEMORY = 5_000 ## Længde af buffer\n",
    "        self.memory = deque(maxlen=self.MAX_MEMORY)  ## popleft() buffer\n",
    "        self.BATCH_SIZE = 32 ## Sample størrelse\n",
    "        self.LR = learning_rate ## Learning rate (TIDLIGERE 0.01 for onestep)\n",
    "        if device is not None: ## Her kan man vælge at køre cpu selvom man har cuda\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        inputs = inputs + len(self.data.T) -1\n",
    "        self.model = Linear_QNet(inputs=inputs).to(self.device) \n",
    "        self.model_name = model_name\n",
    "\n",
    "        ## Definerer en masse variable baseret på __init__ input\n",
    "        self.is_training = training\n",
    "        self.file_path = file_path\n",
    "\n",
    "        ## Hvis vi har en sti til en model, vil vi loade den i stedet for at træne en ny\n",
    "        if self.file_path is not None:\n",
    "            self.model.load_state_dict(torch.load(self.file_path, map_location=self.device))\n",
    "            self.model.eval()\n",
    "\n",
    "        ## Initialisér trainer\n",
    "        self.trainer = QTrainer(self.model, lr=self.LR)\n",
    "\n",
    "\n",
    "        ## Gemmer state-actionpar til buffer\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "        ## Træner long memory\n",
    "    def train_long_memory(self):\n",
    "        if len(self.memory) > self.BATCH_SIZE:\n",
    "            mini_sample = random.sample(self.memory, self.BATCH_SIZE) # list of tuples\n",
    "        else:\n",
    "            mini_sample = self.memory\n",
    "\n",
    "        states, actions, rewards, next_states, dones = zip(*mini_sample)\n",
    "        self.trainer.train_step(states, actions, rewards, next_states, dones, self.target_model)\n",
    "\n",
    "        ## Træner short memory\n",
    "    def train_short_memory(self, state, action, reward, done, outcome):\n",
    "        self.trainer.train_step(state, action, reward, done, outcome)\n",
    "\n",
    "        ## Bestem en action\n",
    "    def get_action(self, state):\n",
    "\n",
    "        final_move = torch.tensor([0,0])\n",
    "\n",
    "        ## Laver state om til tensor og får en prediction fra modellen\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float).to(self.device).clone().detach()\n",
    "        prediction = self.model(state_tensor)\n",
    "\n",
    "        ## Vælger den class med højeste værdi\n",
    "        move = torch.argmax(prediction).item()\n",
    "        final_move[move] = 1\n",
    "\n",
    "        return final_move\n",
    "    \n",
    "    def train(self, rounds, pcs, loading=False, evaluating=False):\n",
    "        accur = np.zeros(rounds)\n",
    "        lower_acc = np.zeros(rounds)\n",
    "        upper_acc = np.zeros(rounds)\n",
    "        pos_accuracy = np.zeros(rounds)\n",
    "        neg_accuracy = np.zeros(rounds)\n",
    "        pos_outcome_tracker = []\n",
    "        neg_outcome_tracker = []\n",
    "        misclassified_obs = []\n",
    "        for j in range(rounds):\n",
    "            res = []\n",
    "            for i in range(len(self.data)):\n",
    "                state = self.data[i,:len(self.data.T)-1]\n",
    "                pc_vals = [pc @ state for pc in pcs]\n",
    "                state = np.concatenate((state, pc_vals))\n",
    "                outcome = self.data[i,-1]\n",
    "                outcome = torch.tensor([1,0] if outcome == 1 else [0,1])\n",
    "                decision = self.get_action(state)\n",
    "                reward = 0\n",
    "                if list(decision) == list(outcome): reward = 1\n",
    "\n",
    "                if list(outcome) == [1,0]:\n",
    "                    ## Personen fik diabetes\n",
    "                    if list(decision) == [1,0]: pos_outcome_tracker.append(1)\n",
    "                    else: pos_outcome_tracker.append(0)\n",
    "                else:\n",
    "                    ## Personen fik ikke diabetes\n",
    "                    if list(decision) == [0,1]: neg_outcome_tracker.append(1)\n",
    "                    else: neg_outcome_tracker.append(0)\n",
    "\n",
    "                if self.is_training: \n",
    "                    self.train_short_memory(state, decision, reward, done=True, outcome=outcome)\n",
    "                else: \n",
    "                    if reward == 0: misclassified_obs.append(self.data[i])\n",
    "\n",
    "                res.append(reward)\n",
    "\n",
    "            p_hat = np.mean(res)\n",
    "            lower, upper =p_hat - 1.96*np.sqrt((p_hat*(1-p_hat))/len(res)), p_hat + 1.96*np.sqrt((p_hat*(1-p_hat))/len(res))\n",
    "\n",
    "            if j % (rounds/20) == 0 and loading:\n",
    "                print(f'Loading: {int((j)/rounds*100)}%'*self.is_training,'Mean', round(np.mean(res),2), \n",
    "                      'CI:', round(lower,2), round(upper,2))\n",
    "                \n",
    "            accur[j] = np.mean(res)\n",
    "            lower_acc[j], upper_acc[j] = lower, upper\n",
    "        self.model.save()\n",
    "        \n",
    "        if evaluating:\n",
    "            pos_accuracy = np.mean(pos_outcome_tracker)\n",
    "            neg_accuracy = np.mean(neg_outcome_tracker)\n",
    "            return accur[0], lower_acc[0], upper_acc[0], pos_accuracy, neg_accuracy, misclassified_obs\n",
    "\n",
    "        return np.concatenate(([accur], [lower_acc], [upper_acc]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file to pd DataFrame\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Replace 0's with NaN in columns where 0's are not possible\n",
    "for col in df.columns:\n",
    "    if col in ['Pregnancies', 'Outcome']:\n",
    "        continue\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "\n",
    "# Remove NaN rows in data\n",
    "def remove_nan(DataFrame):\n",
    "    return DataFrame.dropna()\n",
    "\n",
    "def impute_nan(DataFrame, n=None):\n",
    "    global n_nearest_neighbors\n",
    "    imputer = KNNImputer(n_neighbors=(n if n is not None else n_nearest_neighbors))\n",
    "    imputed_array = imputer.fit_transform(DataFrame)\n",
    "    imputed_df = pd.DataFrame(data=imputed_array, columns=DataFrame.columns)\n",
    "    return  imputed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(DataFrame):\n",
    "    # Calculate the mean and standard deviation for each column\n",
    "    means = DataFrame.mean()\n",
    "    stds = DataFrame.std()\n",
    "\n",
    "    global std_threshold\n",
    "\n",
    "    # Create boolean DataFrame indicating whether or not observations exceed threshold\n",
    "    conditions = (DataFrame < (means - std_threshold * stds)) | (DataFrame > (means + std_threshold * stds))\n",
    "\n",
    "    # Any row that should be removed will have at least one True in the conditions DataFrame\n",
    "    rows_to_remove = conditions.any(axis=1)\n",
    "\n",
    "    # Remove the rows that meet the condition\n",
    "    DataFrame = DataFrame[~rows_to_remove]\n",
    "    return DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into k groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_split(DataFrame, k, RemoveOutliers=False, ImputeMissing=False, log_transform=None):\n",
    "    'If not ImputeMissing, NaNs will be removed. NaNs will always be removed in test data.'\n",
    "\n",
    "    ## Get the global features variable\n",
    "    global features\n",
    "\n",
    "    ## Log transformation\n",
    "    if log_transform is not None:\n",
    "        for col in log_transform:\n",
    "            ## Make sure that we are not log-transforming non-existent columns\n",
    "            if col in features:\n",
    "                df[col] = df[col].apply(lambda x: np.log1p(x))\n",
    "\n",
    "    ## Shuffle the DataFrame\n",
    "    shuffled = DataFrame.sample(frac=1)\n",
    "\n",
    "    ## Split into k groups\n",
    "    groups = np.array_split(shuffled, k)\n",
    "\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    pc_array = []\n",
    "\n",
    "\n",
    "    for i in range(k):\n",
    "        groups_copy = groups.copy()\n",
    "        test_data = groups_copy.pop(i)\n",
    "\n",
    "        training_frames = pd.concat(groups_copy)\n",
    "        if ImputeMissing:\n",
    "            training_frames = impute_nan(DataFrame=training_frames)\n",
    "        else:\n",
    "            training_frames = remove_nan(DataFrame=training_frames)\n",
    "        if RemoveOutliers:\n",
    "            training_frames = remove_outliers(DataFrame=training_frames)\n",
    "        training_standard = training_frames.loc[:, features].values\n",
    "\n",
    "        ## Create instance of StandardScaler and fit it on the training data\n",
    "        ## by fitting on training data, we ensure avoidance of information leakage from test data\n",
    "        scaler = StandardScaler().fit(training_standard)\n",
    "\n",
    "        ## Transofmr training data\n",
    "        training_standard = scaler.transform(training_standard)\n",
    "        \n",
    "        ## Add Outcome column to training data\n",
    "        training_standard = np.column_stack((training_standard, training_frames['Outcome']))\n",
    "        X_data.append(training_standard)\n",
    "\n",
    "        ## We do not want to impute the NaNs on the data, we are using to evaluate the model.\n",
    "        ## In this case, NaNs will be removed. Outliers will stay - may want to change that.\n",
    "        test_data = remove_nan(DataFrame=test_data)\n",
    "        if RemoveOutliers:\n",
    "            test_data = remove_outliers(DataFrame=test_data)\n",
    "        test_standard = test_data.loc[:, features].values\n",
    "\n",
    "        ## Standardize the test data according to the mean and std of training data\n",
    "        test_standard = scaler.transform(test_standard)\n",
    "\n",
    "        ## Add Outcome to test data\n",
    "        test_standard = np.column_stack((test_standard, test_data['Outcome']))\n",
    "        Y_data.append(test_standard)\n",
    "\n",
    "\n",
    "        ## Perform PCA\n",
    "        %run pca.ipynb \n",
    "        data_drop_outcome = np.array([row[:-1] for row in X_data[i]])\n",
    "        Vh = get_PCs(data_drop_outcome)\n",
    "        pc_array.append(Vh)\n",
    "\n",
    "    return X_data, Y_data, np.array(pc_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(training_data, test_data, pcs, n_pcs, learning_rate, rtt, plot=False, loading=False):\n",
    "    print(f'Working on:', 'CUDA' if torch.cuda.is_available() else 'CPU')\n",
    "    validation_stats = []\n",
    "    mco_frames = []\n",
    "    for i in range(len(training_data)):\n",
    "        X= training_data[i]\n",
    "        Y = test_data[i]\n",
    "\n",
    "        components = [pcs[i][j] for j in range(n_pcs)]\n",
    "\n",
    "\n",
    "        agent = Agent(learning_rate=learning_rate, data=X, inputs=n_pcs)\n",
    "        training_accuracy = agent.train(rtt, loading=loading, pcs=components)\n",
    "        if plot:\n",
    "            sns.lineplot(pd.DataFrame(training_accuracy.T, columns=['Accuracy', 'CI Lower Bound', 'CI Upper Bound']))\n",
    "            plt.xlabel('Rounds')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title('Training Accuracy')\n",
    "\n",
    "        if loading: print('\\nEval')\n",
    "        agent = Agent(training=False, file_path='Classifier_models/model/0_model.pth', data=Y, inputs=n_pcs)\n",
    "        final_stats = agent.train(1, loading=loading, pcs=components, evaluating=True)\n",
    "        final_accuracy, final_lower_bound, final_upper_bound, positive_acc, negative_acc, mco = final_stats\n",
    "        print(i+1,round(final_accuracy,2))\n",
    "        print('False Negative %', np.round(1-positive_acc,2), 'False Positive %', np.round(1-negative_acc,2),'\\n')\n",
    "        print('Misclassified observations:', len(mco), '/', len(Y))\n",
    "        global features\n",
    "        mco_frames.append(pd.DataFrame(mco, columns=np.concatenate((features, ['Outcome']), axis=0)))\n",
    "\n",
    "        if plot:\n",
    "            plt.errorbar(x=rtt, y= final_accuracy, yerr=(final_upper_bound-final_lower_bound)/2, elinewidth=1, \n",
    "            capsize=10)\n",
    "            plt.show()\n",
    "        validation_stats.append(final_stats)\n",
    "    return validation_stats, pd.concat(mco_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pvest\\anaconda3\\envs\\mldm\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: CUDA\n",
      "1 0.82\n",
      "False Negative % 0.24 False Positive % 0.14 \n",
      "\n",
      "Misclassified observations: 7 / 39\n",
      "2 0.72\n",
      "False Negative % 0.3 False Positive % 0.26 \n",
      "\n",
      "Misclassified observations: 12 / 43\n",
      "3 0.9\n",
      "False Negative % 0.22 False Positive % 0.07 \n",
      "\n",
      "Misclassified observations: 4 / 39\n",
      "4 0.88\n",
      "False Negative % 0.33 False Positive % 0.03 \n",
      "\n",
      "Misclassified observations: 5 / 41\n",
      "5 0.65\n",
      "False Negative % 0.36 False Positive % 0.35 \n",
      "\n",
      "Misclassified observations: 13 / 37\n",
      "6 0.77\n",
      "False Negative % 0.55 False Positive % 0.12 \n",
      "\n",
      "Misclassified observations: 10 / 43\n",
      "7 0.74\n",
      "False Negative % 0.55 False Positive % 0.12 \n",
      "\n",
      "Misclassified observations: 9 / 35\n",
      "8 0.72\n",
      "False Negative % 0.5 False Positive % 0.23 \n",
      "\n",
      "Misclassified observations: 10 / 36\n",
      "9 0.78\n",
      "False Negative % 0.62 False Positive % 0.04 \n",
      "\n",
      "Misclassified observations: 9 / 40\n",
      "10 0.78\n",
      "False Negative % 0.44 False Positive % 0.05 \n",
      "\n",
      "Misclassified observations: 8 / 37\n",
      "Mean: 0.78 Std 0.07 Min/Max 0.65 0.9 Mean CI: 0.65 0.9 Mean False Negatives: 0.41 Mean False Positives: 0.14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833395</td>\n",
       "      <td>1.091250</td>\n",
       "      <td>0.137244</td>\n",
       "      <td>0.356130</td>\n",
       "      <td>0.829634</td>\n",
       "      <td>-0.467171</td>\n",
       "      <td>0.673180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.690066</td>\n",
       "      <td>-0.008936</td>\n",
       "      <td>-0.511099</td>\n",
       "      <td>0.142483</td>\n",
       "      <td>0.574778</td>\n",
       "      <td>0.284417</td>\n",
       "      <td>0.156453</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.791191</td>\n",
       "      <td>1.424640</td>\n",
       "      <td>0.785587</td>\n",
       "      <td>1.531189</td>\n",
       "      <td>-0.884472</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>1.445624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.006559</td>\n",
       "      <td>-0.809071</td>\n",
       "      <td>0.299329</td>\n",
       "      <td>0.356130</td>\n",
       "      <td>-0.390228</td>\n",
       "      <td>1.276513</td>\n",
       "      <td>0.061536</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833395</td>\n",
       "      <td>0.757861</td>\n",
       "      <td>-0.024842</td>\n",
       "      <td>-0.177987</td>\n",
       "      <td>1.100830</td>\n",
       "      <td>0.224290</td>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.814891</td>\n",
       "      <td>1.509636</td>\n",
       "      <td>0.151322</td>\n",
       "      <td>-1.258095</td>\n",
       "      <td>0.359122</td>\n",
       "      <td>-1.335365</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.832832</td>\n",
       "      <td>1.081632</td>\n",
       "      <td>0.480998</td>\n",
       "      <td>1.390073</td>\n",
       "      <td>0.313962</td>\n",
       "      <td>2.070379</td>\n",
       "      <td>-0.463552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.647037</td>\n",
       "      <td>-0.959615</td>\n",
       "      <td>-0.837706</td>\n",
       "      <td>-2.361498</td>\n",
       "      <td>1.295614</td>\n",
       "      <td>-0.705227</td>\n",
       "      <td>1.063285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.726568</td>\n",
       "      <td>-0.465765</td>\n",
       "      <td>-0.837706</td>\n",
       "      <td>0.176330</td>\n",
       "      <td>-0.705149</td>\n",
       "      <td>0.645068</td>\n",
       "      <td>-0.702037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.281595</td>\n",
       "      <td>0.752399</td>\n",
       "      <td>-1.167383</td>\n",
       "      <td>0.507351</td>\n",
       "      <td>0.255675</td>\n",
       "      <td>-0.105096</td>\n",
       "      <td>-0.702037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0      0.833395  1.091250       0.137244       0.356130  0.829634 -0.467171   \n",
       "1     -1.690066 -0.008936      -0.511099       0.142483  0.574778  0.284417   \n",
       "2     -0.791191  1.424640       0.785587       1.531189 -0.884472  0.058940   \n",
       "3      1.006559 -0.809071       0.299329       0.356130 -0.390228  1.276513   \n",
       "4      0.833395  0.757861      -0.024842      -0.177987  1.100830  0.224290   \n",
       "..          ...       ...            ...            ...       ...       ...   \n",
       "3     -0.814891  1.509636       0.151322      -1.258095  0.359122 -1.335365   \n",
       "4      0.832832  1.081632       0.480998       1.390073  0.313962  2.070379   \n",
       "5      1.647037 -0.959615      -0.837706      -2.361498  1.295614 -0.705227   \n",
       "6     -1.726568 -0.465765      -0.837706       0.176330 -0.705149  0.645068   \n",
       "7     -0.281595  0.752399      -1.167383       0.507351  0.255675 -0.105096   \n",
       "\n",
       "         Age  Outcome  \n",
       "0   0.673180      0.0  \n",
       "1   0.156453      1.0  \n",
       "2   1.445624      0.0  \n",
       "3   0.061536      1.0  \n",
       "4   0.751690      0.0  \n",
       "..       ...      ...  \n",
       "3   0.161255      1.0  \n",
       "4  -0.463552      0.0  \n",
       "5   1.063285      1.0  \n",
       "6  -0.702037      1.0  \n",
       "7  -0.702037      1.0  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Decide on k\n",
    "k = 10\n",
    "\n",
    "## Define threshold as 4 standard deviations from mean\n",
    "std_threshold = 4\n",
    "\n",
    "## Define how many nearest neighbors to use in potential imputation\n",
    "n_nearest_neighbors = 3\n",
    "\n",
    "## How many times to go train on the dataset before evaluating?\n",
    "rounds_to_train = 5\n",
    "\n",
    "## How many principal components should be used?\n",
    "number_of_pcs = 0\n",
    "\n",
    "## Learning Rate\n",
    "LR = 0.000009\n",
    "\n",
    "# Which coloumns to drop when standardizing and giving to model. 'Outcome' should be dropped\n",
    "# If any other columns shold be dropped (for feature engineering purposes), these can be specified here as well:\n",
    "drop_coloumns = ['Outcome', 'DiabetesPedigreeFunction']\n",
    "\n",
    "# Which columns to log-transform?\n",
    "log_columns = ['Pregnancies', 'Insulin', 'DiabetesPedigreeFunction', 'Age']\n",
    "\n",
    "# Get all remaining columns in lists\n",
    "features = [col for col in df.columns if col not in [kol for kol in drop_coloumns]]\n",
    "\n",
    "## Create Data from DataFrame\n",
    "X_data, Y_data, pc_array = k_split(df, k=k, RemoveOutliers=True, ImputeMissing=True, log_transform=log_columns)\n",
    "\n",
    "\n",
    "## Perform cross validation\n",
    "statistics, misclassified_observations = cross_validate(X_data,Y_data,pc_array, n_pcs=number_of_pcs, \n",
    "                                            learning_rate = LR, rtt=rounds_to_train, plot=False)\n",
    "\n",
    "## Analyze the data\n",
    "means, low_means, high_means, false_negatives, false_positives = [], [], [], [], []\n",
    "for run_stat in statistics:\n",
    "    means.append(run_stat[0])\n",
    "    low_means.append(run_stat[1])\n",
    "    high_means.append(run_stat[2])\n",
    "    false_negatives.append(1-run_stat[3])\n",
    "    false_positives.append(1-run_stat[4])\n",
    "    \n",
    "print('Mean:', np.round(np.mean(means),2), 'Std', np.round(np.std(means),2), 'Min/Max', np.round(min(means),2), \n",
    "      np.round(max(means),2), 'Mean CI:', np.round(np.mean(low_means),2), np.round(np.mean(high_means),2),\n",
    "      'Mean False Negatives:', np.round(np.mean(false_negatives),2), \n",
    "      'Mean False Positives:', np.round(np.mean(false_positives),2))\n",
    "display(misclassified_observations)\n",
    "\n",
    "\n",
    "# lr 0.0001, 50 runder: Mean 0.83 CI: 0.75 0.92 \n",
    "# lr 0.0001, 20 runder, pc1 + pc2: Mean 0.85 CI: 0.77 0.93  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
